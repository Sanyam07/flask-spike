"""
The common interface for all diverse sampling methods.
"""

import graphlab as _gl

import graphlab.connect.main as glconnect
import graphlab.connect as _mt
from graphlab.toolkits._model import CustomModel as _CustomModel
from graphlab.util import _make_internal_url
from graphlab.util import _raise_error_if_not_of_type

def create(data, item_id = None, quality_feature=None, similarity_features=None):
  """
  Create a diverse sampler that samples from a given set of items.

  Parameters
  ----------
  data : SFrame or SGraph 
    Original reference data. The reference data must contain at least some item
    ID, as other features can be added by using side data with the sample()
    method. If the quality_feature or similarity_features exist in this
    reference data, then those features will be used when sampling if no side
    data is provided. This can be used to sample from some initial ground set.

    The diversity toolkit will either use a user- defined set of similarities
    when given an SGraph, or calculate them on-the- fly when given an SFrame.
    For an SGraph, the quality feature must be attached to each vertex as a
    field, while the similarities must be defined on the edges connecting
    vertices. For an SFrame, a single column will be used for item qualities,
    while a set of columns can be used to compute inter-item similarity.

  item_id : string, required 
    This is a unique identifier for each item in the list. An item_id is
    required, as it is possible to only sample from a subset of the ground set
    by providing a list of item_ids to the sample() method.

  quality_feature : optional 
    The single numeric feature to be used to sample high-quality items. In the
    case of an SFrame, this must be a column name. For an SGraph, this must be a
    vertex field. If no quality feature is specified, then the sampler will only
    consider item similarity when choosing items. In other words, the qualities
    of the items are set to the same value. TODO: implement this

  similarity_features : list[string], optional
    The set of features used to compute similarity between two items. The
    features are weighted equally. That is, the similarity between two
    single numeric features is weighted the same as the similarity between
    two vectors of numeric features. The similarity is computed using the
    method specified in the similarity_function keyword argument. In the
    case of an SFrame, the names must correspond to columns, while in an
    SGraph, they must correspond to edge fields.

    If no similarity features are given, then only the item qualities are
    considered when choosing items.

  Returns
  -------
  out: A DiverseSampler model.

  References (TODO)
  ----------
  - DPP for machine learning
  - Ipsen sampling
  - Weighted vertex cover

  Examples
  --------
  A diverse sampler can be created directly from an SFrame.
  >>> sf = graphlab.SFrame.read_csv(
        'https://s3.amazonaws.com/dato-datasets/auto-mpg/auto-mpg.csv')
  >>> sampler = graphlab.diversity.diverse_sampler.create(data=sf, 
                                            item_id='name', 
                                            quality_feature='accel', 
                                            similarity_features=['mpg', 
                                                                 'displ', 
                                                                 'hp', 
                                                                 'weight'])

  You can also create a diverse sampler with an SGraph:

  >>> sg = graphlab.diversity.create_similarity_graph(data=sf, 
                                                      item_id='name',
                                                      quality_feature='accel',
                                                      similarity_features=['mpg', 'displ', 'hp', 'weight'],
                                                      num_neighbors=10)
  >>> sampler = graphlab.diversity.diverse_sampler.create(data=sg, 
                                                          item_id='name', 
                                                          quality_feature='accel', 
                                                          similarity_features=['similarity'])

  As shown above, you can use the convenience function create_similarity_graph,
  which will construct a similarity graph using the given features. You can also
  manually create your own SGraph, as long as there is a "similarity" field on
  the edges that represents the similarity between two vertices.



  """
  proxy = _gl.extensions.diverse_sampler()
  sampler = DiverseSampler(data=data, 
                           item_id=item_id,
                           quality_feature=quality_feature,
                           similarity_features=similarity_features,
                           model_proxy = proxy)

  return sampler

class DiverseSampler(_CustomModel):

  def __init__(self, 
               data=None,
               item_id=None,
               quality_feature=None,
               similarity_features=None,
               model_proxy = None,
               _class = None):
    """ 
    Create a DiverseSampler object. This should never be called directly,
    because it is necessary to set up an SDK proxy prior to calling __init__.
    """

    # TODO: if quality feature is none, sample uniformly. If similarity features
    # are None, then just create a quality only sampler (and notify user of this).
    if _class:
      self.__class__ = _class

    self.__proxy__ = model_proxy
    self.__name__ = 'diverse_sampler'

    if item_id is None and model_proxy is None:
      raise ValueError("An item_id must be specified.")

    if data is None and model_proxy is None:
      raise ValueError("The diverse sampler must be initialized with a reference SFrame or SGraph.")

    if isinstance(data, _gl.SFrame):
      opts = dict()
      opts["item_id"] = item_id
      opts["quality_feature"] = quality_feature
      opts["similarity_features"] = similarity_features
      self.__proxy__.init_with_frame(data, opts)

    elif isinstance(data, _gl.SGraph):
      opts = dict()
      if len(similarity_features) > 1:
        raise ValueError("Only 1 similarity feature is supported for SGraph.")

      opts["item_id"] = item_id
      opts["quality_feature"] = quality_feature
      opts["similarity_features"] = similarity_features
      self.__proxy__.init_with_graph(data, opts)

    elif data is not None:
      raise ValueError("Unknown data type " + str(type(data)) + ".")


  def sample(self, k, diversity=0.5, method=None, side_data=None, **kwargs):
    """
    After constructing a diverse sampler, sample a diverse set stochastically.
    The stochastic algorithm depends on the sampling method itself.

    Parameters
    ----------
    k : int
      The number of items to sample.

    diversity : double in [0, 1], optional 
      This is a tunable parameter that trades off between quality and diversity.
      A diversity factor of 0 will only consider quality when building a set
      (equivalent to using the method "quality_only"), while a diversity factor
      of 1 will only consider item similarity and will ignore quality. A value
      between 0 and 1 will force the algorithm to trade off between quality and
      diversity.

      The actual effect of the diversity factor depends on the algorithm:
        - When method="weighted_vertex_cover", the diversity factor changes the
          number of nearest-neighbors to remove when sampling an item.
          Specifically, the number of neighbors is set to the value floor(
          (N-1)/(k-1) * diversity_factor).

        - When method="ipsen", the diversity factor will scale the similarity
          values by the value of diversity, and the quality values by
          (1-diversity).

    method : {'random', 'quality_only', 'weighted_vertex_cover', 'ipsen'},
              optional
      The sampling method to use. The options available are:

      - *"random"*: Returns a completely random set of items, with no reference
        to item qualities or similarities. Note that the greedy method is
        undefined for a random sampler.

      - *"quality_only"*: Form a sampling distribution with the item qualities,
        and return a set from this distribution. The sample() method will sample
        a set from this distribution, while the greedy() method will return the
        top-k items according to item quality. 

        Requirements: The column quality_feature must be present.

      - *"ipsen"*: Sample a diverse set using an approximation to the log-
        determinant. 

        One method of sampling diverse sets is to use determinantal point
        process (DPP) sampling (see: http://arxiv.org/abs/1207.6083). Given any
        set of items, one measure of diversity is the log-determinant of the
        items' similarity matrix L. The diagonal entry L_{ii} corresponds to the
        quality of item i, while the off-diagonal entries L_{ij} correspond to
        the similarity between items i and j. The log-determinant of this matrix
        corresponds directly to the joint quality-diversity of the items that
        define L (high-qualities lead to a larger value of the determinant,
        while large similarities diminish the log-determinant). However, DPP
        sampling does not scale well, so we can instead approximate the log-
        determinant of a similarity matrix using more scalable methods.

        The Ipsen sampler uses the block-approximation of the determinant given
        in http://arxiv.org/pdf/1105.0437v1.pdf in order to mimic DPP sampling
        in a scalable fashion.

        Requirements: The columns quality_feature and similarity_features
        must be present.

      - *"weighted_vertex_cover"*: Sample a set of items with high quality, and
        with no (or a minimum) of nearest-neighbors also in the set. Given a
        graph with a quality field on the vertices and edges connecting similar
        items, for each item, this algorithm either samples from a distribution
        formed by item qualities or selects the item with the maximum quality,
        and then "covers" (or removes from consideration) that item's neighbors.

        There are two options depending on whether you pass in an SGraph or an
        SFrame. You can:
         1. Define similarity by passing in an SGraph, where an edge between two
            vertices denotes the fact that those items are neighbors. Any time a
            point is sampled, all of its neighbors in the graph are removed.
         2. Or, you can pass in an SFrame and the additional keyword argument
            "num_neighbors". Then when a point is sampled, its num_neighbors
            nearest-neighbors will be removed from consideration.

        Requirements: The parameters quality_feature and similarity_features
        must be defined (where they either match column names or vertex and edge
        fields).

      If no sampling_method is given, then the default option is to use the
      weighted_vertex_cover algorithm with a diversity factor of 0.1.

    side_data: sframe, optional
      An ID-based subset of the original data to sample from. Sometimes you may
      wish to sample from only a subset of the original data - e.g., only
      provide a diverse sample of movies from a particular user's top
      recommendations. In addition, some features may not be initially available
      when creating the sampler object. In order to sample from a subset of IDs,
      with the option to add additional features, set side_data to  an SFrame
      with a column of IDs and (optionally) additional features. Note that the
      model must be aware of these initial features when creating it by adding
      the column names for the side-quality or side-similarity features.

      The sampler will first subset the groundset by the list of IDs passed.
      Then the sampler will use any updated or additional quality or similarity
      features in side_data. If some feature is not available in side_data, the
      sampler uses the original features in the SFrame or SGraph passed in with
      create().

      If side_data is empty, then the sampler will return subsets from the
      original SFrame or SGraph passed in with the data parameter used in
      create().

    similarity_function : string
      TODO: I haven't added this yet

    **kwargs : optional
      Additional method-specific parameters for fine-tuning.

      - *wvc_neighbors*: For sampling_method=weighted_vertex_cover and a
        sampler constructed with an SFrame, remove num_neighbors when a point
        is sampled.

    Examples
    --------
    Sample k items directly from the ground set passed in via create() with the
    default sampling methods:

    >>> sf = graphlab.SFrame.read_csv(
          'https://s3.amazonaws.com/dato-datasets/auto-mpg/auto-mpg.csv')
    >>> sampler = graphlab.diversity.diverse_sampler.create(data=sf, 
                                              item_id='name', 
                                              quality_feature='accel', 
                                              similarity_features=['mpg', 
                                                                   'displ', 
                                                                   'hp', 
                                                                   'weight'])
    >>> sampler.sample(k=5)
    +-----+-----+-------+-----+--------+-------+----+--------+----------------------+
    | mpg | cyl | displ |  hp | weight | accel | yr | origin |         name         |
    +-----+-----+-------+-----+--------+-------+----+--------+----------------------+
    |  15 |  8  | 318.0 | 150 |  3777  |  12.5 | 73 |   1    | dodge coronet custom |
    |  15 |  6  | 258.0 | 110 |  3730  |  19.0 | 75 |   1    |     amc matador      |
    |  30 |  4  |  97.0 |  67 |  1985  |  16.4 | 77 |   3    |      subaru dl       |
    |  34 |  4  |  86.0 |  65 |  1975  |  15.2 | 79 |   3    |   maxda glc deluxe   |
    |  32 |  4  |  98.0 |  70 |  2120  |  15.5 | 80 |   1    |  chevrolet chevette  |
    +-----+-----+-------+-----+--------+-------+----+--------+----------------------+

    This method returns an SFrame (or SGraph, depending on what was used to
    create the sampler) containing the sampled items. If the diverse sampler was
    created with an SGraph, the sampler will return an SFrame containing the
    sampled vertices and their associated fields. You can change the sampling
    method with the "method" keyword. The default algorithm is weighted vertex
    cover.

    >>> sf = sampler.sample(k=5, method='ipsen')
    +-----+-----+-------+-----+--------+-------+----+--------+-----------------------+
    | mpg | cyl | displ |  hp | weight | accel | yr | origin |          name         |
    +-----+-----+-------+-----+--------+-------+----+--------+-----------------------+
    |  15 |  8  | 350.0 | 165 |  3693  |  11.5 | 70 |   1    |   buick skylark 320   |
    |  17 |  8  | 302.0 | 140 |  3449  |  10.5 | 70 |   1    |      ford torino      |
    |  15 |  8  | 400.0 | 150 |  3761  |  9.5  | 70 |   1    | chevrolet monte carlo |
    |  22 |  6  | 198.0 |  95 |  2833  |  15.5 | 70 |   1    |    plymouth duster    |
    |  19 |  6  | 232.0 | 100 |  2634  |  13.0 | 71 |   1    |      amc gremlin      |
    +-----+-----+-------+-----+--------+-------+----+--------+-----------------------+

    Instead of stochastic sampling, you can also force the algorithm to try to
    form the best possible set by using the greedy method:

    >>> sf = sampler.sample(k=5, greedy=True)

    It's possible to tune the methods with the "diversity" keyword, which can
    range between 0 and 1. Larger values will favor reducing inter-item
    similarity (increasing diversity), while smaller values will favor high-
    quality items (decreasing diversity).

    >>> sf = sampler.sample(k=5, diversity=0.0, method='ipsen')
    +-----+-----+-------+-----+--------+-------+----+--------+--------------------+
    | mpg | cyl | displ |  hp | weight | accel | yr | origin |        name        |
    +-----+-----+-------+-----+--------+-------+----+--------+--------------------+
    |  14 |  8  | 440.0 | 215 |  4312  |  8.5  | 70 |   1    | plymouth fury iii  |
    |  15 |  8  | 390.0 | 190 |  3850  |  8.5  | 70 |   1    | amc ambassador dpl |
    |  18 |  6  | 199.0 |  97 |  2774  |  15.5 | 70 |   1    |     amc hornet     |
    |  18 |  6  | 232.0 | 100 |  3288  |  15.5 | 71 |   1    |    amc matador     |
    |  11 |  8  | 429.0 | 208 |  4633  |  11.0 | 72 |   1    |  mercury marquis   |
    +-----+-----+-------+-----+--------+-------+----+--------+--------------------+

    >>> sf = sampler.sample(k=5, diversity=1.0, method='ipsen')
    +-----+-----+-------+-----+--------+-------+----+--------+---------------------------+
    | mpg | cyl | displ |  hp | weight | accel | yr | origin |            name           |
    +-----+-----+-------+-----+--------+-------+----+--------+---------------------------+
    |  18 |  8  | 307.0 | 130 |  3504  |  12.0 | 70 |   1    | chevrolet chevelle malibu |
    |  15 |  8  | 350.0 | 165 |  3693  |  11.5 | 70 |   1    |     buick skylark 320     |
    |  18 |  8  | 318.0 | 150 |  3436  |  11.0 | 70 |   1    |     plymouth satellite    |
    |  16 |  8  | 304.0 | 150 |  3433  |  12.0 | 70 |   1    |       amc rebel sst       |
    |  18 |  6  | 171.0 |  97 |  2984  |  14.5 | 75 |   1    |         ford pinto        |
    +-----+-----+-------+-----+--------+-------+----+--------+---------------------------+

    Finally, if you want to restrict the ground set to a smaller subset, you can
    pass in a list of IDs with the "side_data" keyword:

    >>> ford_sf = sf[sf['name'].apply(lambda x: 'ford' in x)]['name']
    >>> sampler.sample(k=5, side_data=graphlab.SFrame({'name':names_sf}))
    +-----------------------+-----+-----+-------+-----+--------+-------+----+--------+
    |          name         | mpg | cyl | displ |  hp | weight | accel | yr | origin |
    +-----------------------+-----+-----+-------+-----+--------+-------+----+--------+
    |  ford pinto runabout  |  21 |  4  | 122.0 |  86 |  2226  |  16.5 | 72 |   1    |
    |     ford maverick     |  18 |  6  | 250.0 |  88 |  3021  |  16.5 | 73 |   1    |
    | ford gran torino (sw) |  14 |  8  | 302.0 | 140 |  4638  |  16.0 | 74 |   1    |
    |  ford fairmont (auto) |  20 |  6  | 200.0 |  85 |  2965  |  15.8 | 78 |   1    |
    |    ford ltd landau    |  17 |  8  | 302.0 | 129 |  3725  |  13.4 | 79 |   1    |
    +-----------------------+-----+-----+-------+-----+--------+-------+----+--------+

    You can also add updated features, or even features that weren't passed in
    when creating the model (as long as they are one of the features specified
    in "quality_feature" or "similarity_featurs"). These new features will be
    joined to the original dataset. However, if any new features were not
    specified in the "similarity_features" parameter during sampler creation,
    they will not be included when computing similarity between items.

    """
    _raise_error_if_not_of_type(k, int)

    if side_data is not None:
      _raise_error_if_not_of_type(side_data, _gl.SFrame)

    opts = dict()

    if method is not None:
      opts["method"] = method

    if diversity < 0.0 or diversity > 1.0:
      raise ValueError("The diversity parameter must be between 0.0 and 1.0.")
    opts["diversity"] = diversity

    if "wvc_neighbors" in kwargs.keys():
      opts["num_neighbors"] = kwargs["wvc_neighbors"]
    if "greedy" in kwargs.keys():
      opts["greedy"] = kwargs["greedy"]

    if side_data is None:
      return self.__proxy__.sample_from_ground_set(k, opts)
    else:
      return self.__proxy__.sample_from_frame_ref_data(k, side_data, opts)


  def save(self, location):
    """
    Save the model. The model is saved as a directory which can then be
    loaded using the :py:func:`~graphlab.load_model` method.

    Note that the diverse_sampler stores the data internally, so you can
    save the model, then load it later and sample from the loaded model
    immediately.

    Parameters
    ----------
    location : string
        Target destination for the model. Can be a local path or remote URL.

    See Also
    ----------
    graphlab.load_model

    Examples
    ----------
    .. sourcecode:: python 
        >>> ground_set = graphlab.SFrame({'id': [0, 1, 2],
                                          'feature_1': [3, 1, 2],
                                          'feature_2': [[0, 1], [0, 1], [1, 0]]})
        >>> sampler = graphlab.diversity.diverse_sampler.create(data=ground_set,
                                                                item_id='id',
                                                                quality_feature='feature_1',
                                                                similarity_features=['feature_2'])
        >>> sampler.save('my_sampler')
        >>> loaded_sampler = graphlab.load_model('my_sampler')
        >>> loaded_sampler.sample(k=2)
        +-----------+------------+----+
        | feature_1 | feature_2  | id |
        +-----------+------------+----+
        |     2     | [0.0, 1.0] | 1  |
        |     1     | [1.0, 0.0] | 2  |
        +-----------+------------+----+

    """
    _mt._get_metric_tracker().track(self.__class__.__module__ + '.save')
    return glconnect.get_unity().save_model(self.__proxy__,
                           _make_internal_url(location), self._get_wrapper())


  def _get_wrapper(self):
    """
    Utility function for save(). This should never be called manually.
    """
    _class = self.__class__
    proxy_wrapper = self.__proxy__._get_wrapper()
    def model_wrapper(unity_proxy):
      model_proxy = proxy_wrapper(unity_proxy)
      return DiverseSampler(model_proxy=model_proxy, _class=_class)
    return model_wrapper
